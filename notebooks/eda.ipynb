{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Procesamiento columna 'Descripción'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "excel_file = pd.ExcelFile('../data/raw/data.xlsx')\n",
    "sheets = excel_file.sheet_names\n",
    "sheets"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Lista de equipos',\n",
       " 'Historico calif 2_1(10 años)',\n",
       " 'T-PAP(C)_T-ACE',\n",
       " 'ARC(I)_ARC(D)',\n",
       " 'DP',\n",
       " 'OIL.TAP',\n",
       " 'DIEL.PF_ DIEL',\n",
       " 'OIL.CORR',\n",
       " 'PRO-M',\n",
       " 'M.OLTC']"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "import unidecode\n",
    "\n",
    "def norm_descrpcion(s):\n",
    "    s = s.lower()\n",
    "    s = unidecode.unidecode(s)\n",
    "    return s\n",
    "\n",
    "converter_descripcion = {}\n",
    "converter_descripcion['Descripción'] = norm_descrpcion\n",
    "\n",
    "df_collection = {}\n",
    "for name in sheets:\n",
    "    df_collection[name] = pd.read_excel('../data/raw/data.xlsx', sheet_name=name, converters=converter_descripcion)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Separar cada fila en cada una de las descripciones. i.e : \"realizar analisis dga, humedad y furanos\" deben quedar dos filas exactamente iguales pero con cada uno de los registros. -> pd.explode(), explode a esa accion de expandir un dataset con base a una regla.\r\n",
    "\r\n",
    "2. Aplicar un algoritmo de distancia de levehnstein. \r\n",
    "\r\n",
    "3. Análisis descriptivo que relacione cada equipo con las acciones. i.e: frecuencias de cada accion para cada equipo."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Separación manual"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "def separacion_manual(dframe, originales, reemplazos, adiciones):\n",
    "    df = dframe.copy()\n",
    "    for i in range(len(originales)):\n",
    "        index = df['Descripción'] == originales[i]\n",
    "        if sum(index) > 0:\n",
    "            instancias = df.loc[index].copy()\n",
    "            df.loc[index,'Descripción'] = reemplazos[i]\n",
    "            df = df.append(instancias, ignore_index = True)\n",
    "            df.loc[len(df) - sum(index):,'Descripción'] = adiciones[i]\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_collection_separados = {}\n",
    "\n",
    "excel_file_reemplazos = pd.ExcelFile('../data/reemplazos_manual/reemplazos_manual.xlsx')\n",
    "sheets_reemplazos = excel_file_reemplazos.sheet_names\n",
    "df_collection_manuales = {}\n",
    "\n",
    "converter_manuales = {}\n",
    "converter_manuales['Originales'] = norm_descrpcion\n",
    "converter_manuales['Reemplazos'] = norm_descrpcion\n",
    "converter_manuales['Adiciones'] = norm_descrpcion\n",
    "\n",
    "for name in sheets_reemplazos:#sheets_reemplazos:\n",
    "    df_collection_manuales[name] = pd.read_excel('../data/reemplazos_manual/reemplazos_manual.xlsx', sheet_name = name, converters = converter_manuales)\n",
    "    index_manuales = ~df_collection_manuales[name].loc[:,'Reemplazos'].isna()\n",
    "    originales = df_collection_manuales[name].loc[index_manuales, 'Originales'].values\n",
    "    reemplazos = df_collection_manuales[name].loc[index_manuales, 'Reemplazos'].values\n",
    "    adiciones = df_collection_manuales[name].loc[index_manuales, 'Adiciones'].values\n",
    "    df_collection_separados[name] = separacion_manual(df_collection[name], originales, reemplazos, adiciones)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Aplicando el algoritmo de distancia de Levenshtein"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Algoritmo de Levenshtein"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "def dist_lev(s1,s2):\n",
    "    dist_matrix = np.zeros((len(s1) + 1, len(s2) + 1))\n",
    "    dist_matrix[1:,0] = range(1,len(s1) + 1)\n",
    "    dist_matrix[0,1:] = range(1,len(s2) + 1)\n",
    "    for i in range(1, len(s1) + 1):\n",
    "        for j in range(1, len(s2) + 1):\n",
    "            if s1[i - 1] == s2[j - 1]:\n",
    "                dist_matrix[i,j] = min(dist_matrix[i - 1, j] + 1, \n",
    "                                    dist_matrix[i - 1, j - 1], \n",
    "                                    dist_matrix[i, j - 1] + 1)\n",
    "            else:\n",
    "                dist_matrix[i,j] = min(dist_matrix[i - 1, j] + 1, \n",
    "                                    dist_matrix[i - 1, j - 1] + 1, \n",
    "                                    dist_matrix[i, j - 1] + 1)\n",
    "    return dist_matrix[-1,-1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Aplicando y ordenando según distancia"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "# Extrayendo valores únicos:\n",
    "ordenados_collection = {}\n",
    "dist_ordenados_collection = {}\n",
    "index_ordenados_collection = {}\n",
    "for name in sheets_reemplazos:\n",
    "    unicos = pd.unique(df_collection_separados[name]['Descripción'])\n",
    "    #Construyendo matriz de distancia de Levenshtein\n",
    "    dist_unicos = np.zeros((len(unicos), len(unicos)))\n",
    "    for i in range(len(unicos)):\n",
    "        for j in range(i + 1, len(unicos)):\n",
    "            dist_unicos[i, j] = dist_lev(unicos[i], unicos[j]) \n",
    "            dist_unicos[j, i] = dist_unicos[i, j]  \n",
    "    #Construyendo array de valores únicos ordenados\n",
    "    #Inizializar varibales\n",
    "    ordenados = ['']*len(unicos)\n",
    "    dist_ordenados = np.zeros(len(unicos))\n",
    "    index_ordenados = np.zeros(len(unicos))\n",
    "    #Ubicando primeros dos elementos\n",
    "    max_dist_index = np.argmax(dist_unicos)\n",
    "    max_dist_index = np.unravel_index(max_dist_index, dist_unicos.shape)\n",
    "\n",
    "    ordenados[0] = unicos[max_dist_index[0]]\n",
    "    dist_ordenados[0] = 0\n",
    "    index_ordenados[0] = max_dist_index[0]\n",
    "            \n",
    "    ordenados[-1] = unicos[max_dist_index[1]]\n",
    "    dist_ordenados[-1] = dist_unicos[max_dist_index]\n",
    "    index_ordenados[-1] = max_dist_index[1]\n",
    "\n",
    "    dist_unicos[max_dist_index] = np.inf\n",
    "    dist_unicos[max_dist_index[1], max_dist_index[0]] = np.inf\n",
    "    #Extrayendo la fila que contiene a la distancia máxima\n",
    "    row_index = max_dist_index[0]\n",
    "    row = dist_unicos[row_index,:]\n",
    "    row[row_index] = np.inf #Elemento de la diagonal\n",
    "    #Ubicando el resto de los elementos\n",
    "    for i in range(1, len(unicos) - 1):\n",
    "        min_index = np.argmin(row)\n",
    "        ordenados[i] = unicos[min_index]\n",
    "        dist_ordenados[i] = dist_unicos[row_index, min_index]\n",
    "        index_ordenados[i] = min_index\n",
    "        dist_unicos[row_index,min_index] = np.inf   \n",
    "\n",
    "    #Ubicándolos por hoja\n",
    "    ordenados_collection[name] = ordenados\n",
    "    dist_ordenados_collection[name] = dist_ordenados\n",
    "    index_ordenados_collection[name] = index_ordenados\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Escribiendo los resultados en Excel"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "import xlsxwriter\n",
    "workbook = xlsxwriter.Workbook('../data/reemplazos_manual/unicos_ordenados.xlsx')\n",
    "for name in sheets_reemplazos:\n",
    "    worksheet = workbook.add_worksheet(name)\n",
    "    for i in range(len(ordenados_collection[name])): \n",
    "        worksheet.write(i,0,ordenados_collection[name][i])\n",
    "        worksheet.write(i,1,ordenados_collection[name][i])\n",
    "        worksheet.write(i,2,dist_ordenados_collection[name][i])\n",
    "        worksheet.write(i,3,index_ordenados_collection[name][i])\n",
    "\n",
    "workbook.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "len(ordenados_collection[name])\n",
    "# workbook.close()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "045885b66cfe0b039a7943055a84c8d63304ae38ee6c28ec31abc449d75a6373"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}